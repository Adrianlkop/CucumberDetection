{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "train_cucumber_fin444.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGo7pCyl__Uh",
        "colab_type": "text"
      },
      "source": [
        "# Instance Segmentation Mask R-CNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUc3oxkCJYAM",
        "colab_type": "text"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcbwNf3MOXFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "7f58420f-cce6-4454-8ae0-021a7a089d12"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun  5 17:55:31 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9LdUPt6AvPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "dfe8fbd8-dd60-44f9-a3a3-fe3f5433310c"
      },
      "source": [
        "!git clone https://github.com/Adrianlkop/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 977, done.\u001b[K\n",
            "remote: Total 977 (delta 0), reused 0 (delta 0), pack-reused 977\u001b[K\n",
            "Receiving objects: 100% (977/977), 116.79 MiB | 13.02 MiB/s, done.\n",
            "Resolving deltas: 100% (580/580), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxy7auWVFxSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d63d169-7109-4559-b5fc-c52aad0d6f85"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDv-5OSJLXd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "8257f932-0c6e-4cc8-b8fd-317ca77f2bba"
      },
      "source": [
        "!pip3 install keras==2.2.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\r\u001b[K     |█                               | 10kB 26.3MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.18.4)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmnjRTZ_AxAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dcaef16-b2c5-4e58-cfb6-1acd97e81beb"
      },
      "source": [
        "cd Mask_RCNN/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXzlTA96AyeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "outputId": "7db62670-1278-4675-c6c2-4ca729fd5c98"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mask_rcnn.egg-info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/mrcnn\n",
            "copying mrcnn/config.py -> build/lib/mrcnn\n",
            "copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
            "copying mrcnn/visualize.py -> build/lib/mrcnn\n",
            "copying mrcnn/utils.py -> build/lib/mrcnn\n",
            "copying mrcnn/__init__.py -> build/lib/mrcnn\n",
            "copying mrcnn/model.py -> build/lib/mrcnn\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
            "Sorry: TabError: inconsistent use of tabs and spaces in indentation (model.py, line 2501)\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.6.egg\n",
            "Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mask-rcnn 2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEA5_zDuA0Uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "25dcf813-51b6-40dc-b797-35bb7ed6b5b8"
      },
      "source": [
        "!pip show mask-rcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: mask-rcnn\n",
            "Version: 2.1\n",
            "Summary: Mask R-CNN for object detection and instance segmentation\n",
            "Home-page: https://github.com/matterport/Mask_RCNN\n",
            "Author: Matterport\n",
            "Author-email: waleed.abdulla@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Requires: \n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31I88xGjBBzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "28452e0b-1d1e-4b91-a2ad-8e8477757550"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBHZC-JcJ2dZ",
        "colab_type": "text"
      },
      "source": [
        "### Software Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5M8NXQ___Ur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33a5f365-6ad7-4ee4-9460-923194448dcd"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import itertools\n",
        "import math\n",
        "import logging\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.lines as lines\n",
        "from matplotlib.patches import Polygon\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content/drive/My Drive/TFG/Via\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "from samples.balloon import cucumber\n",
        "\n",
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKPHLemP394c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHa9STZHKE32",
        "colab_type": "text"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtSvu3UAYelO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cucumberConfig(object):\n",
        "    \"\"\"Base configuration class. For custom configurations, create a\n",
        "    sub-class that inherits from this one and override properties\n",
        "    that need to be changed.\n",
        "    \"\"\"\n",
        "    # Name the configurations. For example, 'COCO', 'Experiment 3', ...etc.\n",
        "    # Useful if your code needs to do things differently depending on which\n",
        "    # experiment is running.\n",
        "    NAME = \"cucumber_cfg\"  # Override in sub-classes\n",
        "\n",
        "    # NUMBER OF GPUs to use. When using only a CPU, this needs to be set to 1.\n",
        "    GPU_COUNT = 1\n",
        "\n",
        "    # Number of images to train with on each GPU. A 12GB GPU can typically\n",
        "    # handle 2 images of 1024x1024px.\n",
        "    # Adjust based on your GPU memory and image sizes. Use the highest\n",
        "    # number that your GPU can handle for best performance.\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    # This doesn't need to match the size of the training set. Tensorboard\n",
        "    # updates are saved at the end of each epoch, so setting this to a\n",
        "    # smaller number means getting more frequent TensorBoard updates.\n",
        "    # Validation stats are also calculated at each epoch end and they\n",
        "    # might take a while, so don't set this too small to avoid spending\n",
        "    # a lot of time on validation stats.\n",
        "    STEPS_PER_EPOCH = 470\n",
        "\n",
        "    # Number of validation steps to run at the end of every training epoch.\n",
        "    # A bigger number improves accuracy of validation stats, but slows\n",
        "    # down the training.\n",
        "    VALIDATION_STEPS = 100\n",
        "\n",
        "    # Backbone network architecture\n",
        "    # Supported values are: resnet50, resnet101.\n",
        "    # You can also provide a callable that should have the signature\n",
        "    # of model.resnet_graph. If you do so, you need to supply a callable\n",
        "    # to COMPUTE_BACKBONE_SHAPE as well\n",
        "    BACKBONE = \"resnet101\"\n",
        "\n",
        "    # Only useful if you supply a callable to BACKBONE. Should compute\n",
        "    # the shape of each layer of the FPN Pyramid.\n",
        "    # See model.compute_backbone_shapes\n",
        "    COMPUTE_BACKBONE_SHAPE = None\n",
        "\n",
        "    # The strides of each layer of the FPN Pyramid. These values\n",
        "    # are based on a Resnet101 backbone.\n",
        "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
        "\n",
        "    # Size of the fully-connected layers in the classification graph\n",
        "    FPN_CLASSIF_FC_LAYERS_SIZE = 1024\n",
        "\n",
        "    # Size of the top-down layers used to build the feature pyramid\n",
        "    TOP_DOWN_PYRAMID_SIZE = 256\n",
        "\n",
        "    # Number of classification classes (including background)\n",
        "    NUM_CLASSES = 1 +1  # Override in sub-classes\n",
        "\n",
        "    # Length of square anchor side in pixels\n",
        "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
        "\n",
        "    # Ratios of anchors at each cell (width/height)\n",
        "    # A value of 1 represents a square anchor, and 0.5 is a wide anchor\n",
        "    RPN_ANCHOR_RATIOS = [0.5, 1, 2]\n",
        "\n",
        "    # Anchor stride\n",
        "    # If 1 then anchors are created for each cell in the backbone feature map.\n",
        "    # If 2, then anchors are created for every other cell, and so on.\n",
        "    RPN_ANCHOR_STRIDE = 1\n",
        "\n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    RPN_NMS_THRESHOLD = 0.7\n",
        "\n",
        "    # How many anchors per image to use for RPN training\n",
        "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
        "    \n",
        "    # ROIs kept after tf.nn.top_k and before non-maximum suppression\n",
        "    PRE_NMS_LIMIT = 6000\n",
        "\n",
        "    # ROIs kept after non-maximum suppression (training and inference)\n",
        "    POST_NMS_ROIS_TRAINING = 2000\n",
        "    POST_NMS_ROIS_INFERENCE = 1000\n",
        "\n",
        "    # If enabled, resizes instance masks to a smaller size to reduce\n",
        "    # memory load. Recommended when using high-resolution images.\n",
        "    USE_MINI_MASK = True\n",
        "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
        "\n",
        "    # Input image resizing\n",
        "    # Generally, use the \"square\" resizing mode for training and predicting\n",
        "    # and it should work well in most cases. In this mode, images are scaled\n",
        "    # up such that the small side is = IMAGE_MIN_DIM, but ensuring that the\n",
        "    # scaling doesn't make the long side > IMAGE_MAX_DIM. Then the image is\n",
        "    # padded with zeros to make it a square so multiple images can be put\n",
        "    # in one batch.\n",
        "    # Available resizing modes:\n",
        "    # none:   No resizing or padding. Return the image unchanged.\n",
        "    # square: Resize and pad with zeros to get a square image\n",
        "    #         of size [max_dim, max_dim].\n",
        "    # pad64:  Pads width and height with zeros to make them multiples of 64.\n",
        "    #         If IMAGE_MIN_DIM or IMAGE_MIN_SCALE are not None, then it scales\n",
        "    #         up before padding. IMAGE_MAX_DIM is ignored in this mode.\n",
        "    #         The multiple of 64 is needed to ensure smooth scaling of feature\n",
        "    #         maps up and down the 6 levels of the FPN pyramid (2**6=64).\n",
        "    # crop:   Picks random crops from the image. First, scales the image based\n",
        "    #         on IMAGE_MIN_DIM and IMAGE_MIN_SCALE, then picks a random crop of\n",
        "    #         size IMAGE_MIN_DIM x IMAGE_MIN_DIM. Can be used in training only.\n",
        "    #         IMAGE_MAX_DIM is not used in this mode.\n",
        "    IMAGE_RESIZE_MODE = \"square\"\n",
        "    IMAGE_MIN_DIM = 800\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "    # Minimum scaling ratio. Checked after MIN_IMAGE_DIM and can force further\n",
        "    # up scaling. For example, if set to 2 then images are scaled up to double\n",
        "    # the width and height, or more, even if MIN_IMAGE_DIM doesn't require it.\n",
        "    # However, in 'square' mode, it can be overruled by IMAGE_MAX_DIM.\n",
        "    IMAGE_MIN_SCALE = 0\n",
        "    # Number of color channels per image. RGB = 3, grayscale = 1, RGB-D = 4\n",
        "    # Changing this requires other changes in the code. See the WIKI for more\n",
        "    # details: https://github.com/matterport/Mask_RCNN/wiki\n",
        "    IMAGE_CHANNEL_COUNT = 3\n",
        "\n",
        "    # Image mean (RGB)\n",
        "    MEAN_PIXEL = np.array([123.7, 116.8, 103.9])\n",
        "\n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    TRAIN_ROIS_PER_IMAGE = 200\n",
        "\n",
        "    # Percent of positive ROIs used to train classifier/mask heads\n",
        "    ROI_POSITIVE_RATIO = 0.33\n",
        "\n",
        "    # Pooled ROIs\n",
        "    POOL_SIZE = 7\n",
        "    MASK_POOL_SIZE = 14\n",
        "\n",
        "    # Shape of output mask\n",
        "    # To change this you also need to change the neural network mask branch\n",
        "    MASK_SHAPE = [28, 28]\n",
        "\n",
        "    # Maximum number of ground truth instances to use in one image\n",
        "    MAX_GT_INSTANCES = 100\n",
        "\n",
        "    # Bounding box refinement standard deviation for RPN and final detections.\n",
        "    RPN_BBOX_STD_DEV = np.array([0.1, 0.1, 0.2, 0.2])\n",
        "    BBOX_STD_DEV = np.array([0.1, 0.1, 0.2, 0.2])\n",
        "\n",
        "    # Max number of final detections\n",
        "    DETECTION_MAX_INSTANCES = 100\n",
        "\n",
        "    # Minimum probability value to accept a detected instance\n",
        "    # ROIs below this threshold are skipped\n",
        "    DETECTION_MIN_CONFIDENCE = 0.7\n",
        "\n",
        "    # Non-maximum suppression threshold for detection\n",
        "    DETECTION_NMS_THRESHOLD = 0.3\n",
        "\n",
        "    # Learning rate and momentum\n",
        "    # The Mask RCNN paper uses lr=0.02, but on TensorFlow it causes\n",
        "    # weights to explode. Likely due to differences in optimizer\n",
        "    # implementation.\n",
        "    LEARNING_RATE = 0.0005\n",
        "    LEARNING_MOMENTUM = 0.9\n",
        "\n",
        "    # Weight decay regularization\n",
        "    WEIGHT_DECAY = 0.0004\n",
        "\n",
        "    # Loss weights for more precise optimization.\n",
        "    # Can be used for R-CNN training setup.\n",
        "    LOSS_WEIGHTS = {\n",
        "        \"rpn_class_loss\": 1.,\n",
        "        \"rpn_bbox_loss\": 1.,\n",
        "        \"mrcnn_class_loss\": 1.,\n",
        "        \"mrcnn_bbox_loss\": 1.,\n",
        "        \"mrcnn_mask_loss\": 1.\n",
        "    }\n",
        "\n",
        "    # Use RPN ROIs or externally generated ROIs for training\n",
        "    # Keep this True for most situations. Set to False if you want to train\n",
        "    # the head branches on ROI generated by code rather than the ROIs from\n",
        "    # the RPN. For example, to debug the classifier head without having to\n",
        "    # train the RPN.\n",
        "    USE_RPN_ROIS = True\n",
        "\n",
        "    # Train or freeze batch normalization layers\n",
        "    #     None: Train BN layers. This is the normal mode\n",
        "    #     False: Freeze BN layers. Good when using a small batch size\n",
        "    #     True: (don't use). Set layer in training mode even when predicting\n",
        "    TRAIN_BN = False  # Defaulting to False since batch size is often small\n",
        "\n",
        "    # Gradient norm clipping\n",
        "    GRADIENT_CLIP_NORM = 5.0\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Set values of computed attributes.\"\"\"\n",
        "        # Effective batch size\n",
        "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
        "\n",
        "        # Input image size\n",
        "        if self.IMAGE_RESIZE_MODE == \"crop\":\n",
        "            self.IMAGE_SHAPE = np.array([self.IMAGE_MIN_DIM, self.IMAGE_MIN_DIM,\n",
        "                self.IMAGE_CHANNEL_COUNT])\n",
        "        else:\n",
        "            self.IMAGE_SHAPE = np.array([self.IMAGE_MAX_DIM, self.IMAGE_MAX_DIM,\n",
        "                self.IMAGE_CHANNEL_COUNT])\n",
        "\n",
        "        # Image meta data length\n",
        "        # See compose_image_meta() for details\n",
        "        self.IMAGE_META_SIZE = 1 + 3 + 3 + 4 + 1 + self.NUM_CLASSES\n",
        "\n",
        "    def display(self):\n",
        "        \"\"\"Display Configuration values.\"\"\"\n",
        "        print(\"\\nConfigurations:\")\n",
        "        for a in dir(self):\n",
        "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
        "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
        "        print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHA4VjG2__Ux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "343fef48-770b-43d6-d12f-51c3fccb8fb0"
      },
      "source": [
        "#config = cucumber.cucumberConfig()\n",
        "config = cucumberConfig()\n",
        "cucumber_DIR = \"/content/drive/My Drive/TFG/Via\"\n",
        "config.display()\n",
        "print(cucumber.cucumberConfig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.0005\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           cucumber_cfg\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                470\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               100\n",
            "WEIGHT_DECAY                   0.0004\n",
            "\n",
            "\n",
            "<class 'samples.balloon.cucumber.cucumberConfig'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBXKavVh__U0",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aKR80py__U0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "94228476-64d0-4059-f838-1c2b1fbf616c"
      },
      "source": [
        "# Load dataset\n",
        "# Get the dataset from the releases page\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "dataset = cucumber.cucumberDataset()\n",
        "dataset.load_cucumber(cucumber_DIR, \"train\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset.num_classes))\n",
        "for i, info in enumerate(dataset.class_info):\n",
        "    print(\"{:3}. {:50}\".format(i, info['name']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Count: 235\n",
            "Class Count: 2\n",
            "  0. BG                                                \n",
            "  1. cucumber                                          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTJhFYF0__Vc",
        "colab_type": "text"
      },
      "source": [
        "## Model preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5d7oo3KHwi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "d46e298c-0851-4277-e961-be53a1a77f67"
      },
      "source": [
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir='/content/drive/My Drive/TFG/Submision/Weight_decay')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:555: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:602: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZKkIlZnIQQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "7b2f1fc0-0ede-45ca-f358-1b4ab243c86f"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/TFG/Via/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXSPBHziJfM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile(self, learning_rate, momentum):\n",
        "        \"\"\"Gets the model ready for training. Adds losses, regularization, and\n",
        "        metrics. Then calls the Keras compile() function.\n",
        "        \"\"\"\n",
        "        # Optimizer object\n",
        "        optimizer = keras.optimizers.SGD(\n",
        "           lr=learning_rate, momentum=momentum,\n",
        "           clipnorm=self.config.GRADIENT_CLIP_NORM)\n",
        "        #optimizer = keras.optimizers.Adam(lr=learning_rate, amsgrad=True, clipnorm=5.0)\n",
        "\n",
        "        \n",
        "        # Add Losses\n",
        "        # First, clear previously set losses to avoid duplication\n",
        "        self.keras_model._losses = []\n",
        "        self.keras_model._per_input_losses = {}\n",
        "        loss_names = [\n",
        "            \"rpn_class_loss\",  \"rpn_bbox_loss\",\n",
        "            \"mrcnn_class_loss\", \"mrcnn_bbox_loss\", \"mrcnn_mask_loss\"]\n",
        "        for name in loss_names:\n",
        "            layer = self.keras_model.get_layer(name)\n",
        "            if layer.output in self.keras_model.losses:\n",
        "                continue\n",
        "            loss = (\n",
        "                tf.reduce_mean(layer.output, keepdims=True)\n",
        "                * self.config.LOSS_WEIGHTS.get(name, 1.))\n",
        "            self.keras_model.add_loss(loss)\n",
        "\n",
        "        # Add L2 Regularization\n",
        "        # Skip gamma and beta weights of batch normalization layers.\n",
        "        reg_losses = [\n",
        "            keras.regularizers.l2(self.config.WEIGHT_DECAY)(w) / tf.cast(tf.size(w), tf.float32)\n",
        "            for w in self.keras_model.trainable_weights\n",
        "            if 'gamma' not in w.name and 'beta' not in w.name]\n",
        "        self.keras_model.add_loss(tf.add_n(reg_losses))\n",
        "\n",
        "        # Compile\n",
        "        self.keras_model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=[None] * len(self.keras_model.outputs))\n",
        "\n",
        "        # Add metrics for losses\n",
        "        for name in loss_names:\n",
        "            if name in self.keras_model.metrics_names:\n",
        "                continue\n",
        "            layer = self.keras_model.get_layer(name)\n",
        "            self.keras_model.metrics_names.append(name)\n",
        "            loss = (\n",
        "                tf.reduce_mean(layer.output, keepdims=True)\n",
        "                * self.config.LOSS_WEIGHTS.get(name, 1.))\n",
        "            self.keras_model.metrics_tensors.append(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9mWtAOuI7jD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mrcnn import utils\n",
        "class cucumberDataset(utils.Dataset):\n",
        "\n",
        "    def load_cucumber(self, dataset_dir, subset):\n",
        "        \"\"\"Load a subset of the Balloon dataset.\n",
        "        dataset_dir: Root directory of the dataset.\n",
        "        subset: Subset to load: train or val\n",
        "        \"\"\"\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"cucumber\", 1, \"cucumber\")\n",
        "\n",
        "        # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "        # Load annotations\n",
        "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
        "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
        "        #   'regions': {\n",
        "        #       '0': {\n",
        "        #           'region_attributes': {},\n",
        "        #           'shape_attributes': {\n",
        "        #               'all_points_x': [...],\n",
        "        #               'all_points_y': [...],\n",
        "        #               'name': 'polygon'}},\n",
        "        #       ... more regions ...\n",
        "        #   },\n",
        "        #   'size': 100202\n",
        "        # }\n",
        "        # We mostly care about the x and y coordinates of each region\n",
        "        # Note: In VIA 2.0, regions was changed from a dict to a list.\n",
        "        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
        "        annotations = list(annotations.values())  # don't need the dict keys\n",
        "\n",
        "        # The VIA tool saves images in the JSON even if they don't have any\n",
        "        # annotations. Skip unannotated images.\n",
        "        annotations = [a for a in annotations if a['regions']]\n",
        "\n",
        "        # Add images\n",
        "        for a in annotations:\n",
        "            # Get the x, y coordinaets of points of the polygons that make up\n",
        "            # the outline of each object instance. These are stores in the\n",
        "            # shape_attributes (see json format above)\n",
        "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
        "            if type(a['regions']) is dict:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
        "            else:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions']] \n",
        "\n",
        "            # load_mask() needs the image size to convert polygons to masks.\n",
        "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
        "            # the image. This is only managable since the dataset is tiny.\n",
        "            image_path = os.path.join(dataset_dir, a['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            self.add_image(\n",
        "                \"cucumber\",\n",
        "                image_id=a['filename'],  # use file name as a unique image id\n",
        "                path=image_path,\n",
        "                width=width, height=height,\n",
        "                polygons=polygons)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        # If not a balloon dataset image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"cucumber\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "        info = self.image_info[image_id]\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"cucumber\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPfVzmZhJvvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir='/content/drive/My Drive/TFG/Via'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_bbV4ywInAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "# Training dataset.\n",
        "dataset_train = cucumberDataset()\n",
        "dataset_train.load_cucumber(dataset_dir, \"train\")\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = cucumberDataset()\n",
        "dataset_val.load_cucumber(dataset_dir, \"val\")\n",
        "dataset_val.prepare()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGAjs7tuQNpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "aug = iaa.OneOf([\n",
        "    iaa.Add((-40, 40)),\n",
        "    iaa.Multiply((0.8, 1.5)),\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Flipud(0.5)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXxsb1vSED52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dir(iaa))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBWtoYVV8wz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngFVKQfeFAPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf9e37a2-6f6c-4bf5-c3df-7fc04aec2b6f"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE*2,\n",
        "                epochs=20,\n",
        "                layers='heads',\n",
        "                augmentation = aug)\n",
        "model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=30,\n",
        "                layers='4+',\n",
        "                augmentation = aug)\n",
        "model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE/5,\n",
        "                epochs=45,\n",
        "                layers='all',\n",
        "                augmentation = aug)\n",
        "print('Elapsed time', round((time.time() - start)/60, 1), 'minutes')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/drive/My Drive/TFG/Submision/Weight_decay/cucumber_cfg20200605T1806/mask_rcnn_cucumber_cfg_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/20\n",
            "470/470 [==============================] - 325s 691ms/step - loss: 1.1653 - rpn_class_loss: 0.0397 - rpn_bbox_loss: 0.3616 - mrcnn_class_loss: 0.1491 - mrcnn_bbox_loss: 0.3277 - mrcnn_mask_loss: 0.2873 - val_loss: 1.3166 - val_rpn_class_loss: 0.0595 - val_rpn_bbox_loss: 0.5104 - val_mrcnn_class_loss: 0.1475 - val_mrcnn_bbox_loss: 0.3340 - val_mrcnn_mask_loss: 0.2653\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/20\n",
            "470/470 [==============================] - 294s 626ms/step - loss: 0.5488 - rpn_class_loss: 0.0119 - rpn_bbox_loss: 0.1753 - mrcnn_class_loss: 0.0768 - mrcnn_bbox_loss: 0.1094 - mrcnn_mask_loss: 0.1754 - val_loss: 1.3198 - val_rpn_class_loss: 0.0398 - val_rpn_bbox_loss: 0.4927 - val_mrcnn_class_loss: 0.1810 - val_mrcnn_bbox_loss: 0.2811 - val_mrcnn_mask_loss: 0.3251\n",
            "Epoch 3/20\n",
            "470/470 [==============================] - 295s 628ms/step - loss: 0.4474 - rpn_class_loss: 0.0074 - rpn_bbox_loss: 0.1563 - mrcnn_class_loss: 0.0564 - mrcnn_bbox_loss: 0.0867 - mrcnn_mask_loss: 0.1406 - val_loss: 1.3578 - val_rpn_class_loss: 0.0597 - val_rpn_bbox_loss: 0.5720 - val_mrcnn_class_loss: 0.1581 - val_mrcnn_bbox_loss: 0.2727 - val_mrcnn_mask_loss: 0.2953\n",
            "Epoch 4/20\n",
            "470/470 [==============================] - 295s 628ms/step - loss: 0.3707 - rpn_class_loss: 0.0052 - rpn_bbox_loss: 0.1354 - mrcnn_class_loss: 0.0440 - mrcnn_bbox_loss: 0.0630 - mrcnn_mask_loss: 0.1230 - val_loss: 1.4396 - val_rpn_class_loss: 0.0722 - val_rpn_bbox_loss: 0.5732 - val_mrcnn_class_loss: 0.2139 - val_mrcnn_bbox_loss: 0.2670 - val_mrcnn_mask_loss: 0.3133\n",
            "Epoch 5/20\n",
            "470/470 [==============================] - 295s 627ms/step - loss: 0.3167 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.1140 - mrcnn_class_loss: 0.0408 - mrcnn_bbox_loss: 0.0518 - mrcnn_mask_loss: 0.1063 - val_loss: 1.4206 - val_rpn_class_loss: 0.0512 - val_rpn_bbox_loss: 0.5559 - val_mrcnn_class_loss: 0.2237 - val_mrcnn_bbox_loss: 0.2543 - val_mrcnn_mask_loss: 0.3355\n",
            "Epoch 6/20\n",
            "470/470 [==============================] - 295s 627ms/step - loss: 0.2591 - rpn_class_loss: 0.0028 - rpn_bbox_loss: 0.0884 - mrcnn_class_loss: 0.0354 - mrcnn_bbox_loss: 0.0367 - mrcnn_mask_loss: 0.0957 - val_loss: 1.5828 - val_rpn_class_loss: 0.0803 - val_rpn_bbox_loss: 0.5563 - val_mrcnn_class_loss: 0.3023 - val_mrcnn_bbox_loss: 0.2698 - val_mrcnn_mask_loss: 0.3741\n",
            "Epoch 7/20\n",
            "470/470 [==============================] - 292s 622ms/step - loss: 0.2234 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0694 - mrcnn_class_loss: 0.0328 - mrcnn_bbox_loss: 0.0322 - mrcnn_mask_loss: 0.0866 - val_loss: 1.7174 - val_rpn_class_loss: 0.0708 - val_rpn_bbox_loss: 0.6269 - val_mrcnn_class_loss: 0.3063 - val_mrcnn_bbox_loss: 0.3050 - val_mrcnn_mask_loss: 0.4083\n",
            "Epoch 8/20\n",
            "470/470 [==============================] - 297s 633ms/step - loss: 0.2313 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0755 - mrcnn_class_loss: 0.0351 - mrcnn_bbox_loss: 0.0343 - mrcnn_mask_loss: 0.0842 - val_loss: 1.5918 - val_rpn_class_loss: 0.0844 - val_rpn_bbox_loss: 0.5253 - val_mrcnn_class_loss: 0.3052 - val_mrcnn_bbox_loss: 0.2750 - val_mrcnn_mask_loss: 0.4020\n",
            "Epoch 9/20\n",
            "470/470 [==============================] - 294s 625ms/step - loss: 0.2337 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0862 - mrcnn_class_loss: 0.0331 - mrcnn_bbox_loss: 0.0321 - mrcnn_mask_loss: 0.0804 - val_loss: 1.5331 - val_rpn_class_loss: 0.0911 - val_rpn_bbox_loss: 0.5207 - val_mrcnn_class_loss: 0.2820 - val_mrcnn_bbox_loss: 0.2319 - val_mrcnn_mask_loss: 0.4075\n",
            "Epoch 10/20\n",
            "470/470 [==============================] - 294s 625ms/step - loss: 0.2134 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0789 - mrcnn_class_loss: 0.0292 - mrcnn_bbox_loss: 0.0281 - mrcnn_mask_loss: 0.0753 - val_loss: 1.6447 - val_rpn_class_loss: 0.0609 - val_rpn_bbox_loss: 0.5005 - val_mrcnn_class_loss: 0.3450 - val_mrcnn_bbox_loss: 0.2690 - val_mrcnn_mask_loss: 0.4693\n",
            "Epoch 11/20\n",
            "470/470 [==============================] - 292s 622ms/step - loss: 0.1641 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0493 - mrcnn_class_loss: 0.0266 - mrcnn_bbox_loss: 0.0195 - mrcnn_mask_loss: 0.0672 - val_loss: 1.6382 - val_rpn_class_loss: 0.0802 - val_rpn_bbox_loss: 0.4966 - val_mrcnn_class_loss: 0.3153 - val_mrcnn_bbox_loss: 0.2617 - val_mrcnn_mask_loss: 0.4843\n",
            "Epoch 12/20\n",
            "470/470 [==============================] - 294s 625ms/step - loss: 0.1662 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0460 - mrcnn_class_loss: 0.0291 - mrcnn_bbox_loss: 0.0217 - mrcnn_mask_loss: 0.0682 - val_loss: 1.4369 - val_rpn_class_loss: 0.0531 - val_rpn_bbox_loss: 0.4745 - val_mrcnn_class_loss: 0.2226 - val_mrcnn_bbox_loss: 0.2306 - val_mrcnn_mask_loss: 0.4560\n",
            "Epoch 13/20\n",
            "470/470 [==============================] - 293s 624ms/step - loss: 0.1815 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0564 - mrcnn_class_loss: 0.0279 - mrcnn_bbox_loss: 0.0256 - mrcnn_mask_loss: 0.0704 - val_loss: 1.7145 - val_rpn_class_loss: 0.0646 - val_rpn_bbox_loss: 0.4790 - val_mrcnn_class_loss: 0.4428 - val_mrcnn_bbox_loss: 0.2596 - val_mrcnn_mask_loss: 0.4685\n",
            "Epoch 14/20\n",
            "470/470 [==============================] - 293s 623ms/step - loss: 0.1347 - rpn_class_loss: 8.6178e-04 - rpn_bbox_loss: 0.0338 - mrcnn_class_loss: 0.0253 - mrcnn_bbox_loss: 0.0146 - mrcnn_mask_loss: 0.0602 - val_loss: 1.7356 - val_rpn_class_loss: 0.0724 - val_rpn_bbox_loss: 0.5063 - val_mrcnn_class_loss: 0.3762 - val_mrcnn_bbox_loss: 0.2468 - val_mrcnn_mask_loss: 0.5340\n",
            "Epoch 15/20\n",
            "470/470 [==============================] - 295s 628ms/step - loss: 0.1189 - rpn_class_loss: 6.7866e-04 - rpn_bbox_loss: 0.0232 - mrcnn_class_loss: 0.0242 - mrcnn_bbox_loss: 0.0132 - mrcnn_mask_loss: 0.0575 - val_loss: 1.6872 - val_rpn_class_loss: 0.0774 - val_rpn_bbox_loss: 0.5192 - val_mrcnn_class_loss: 0.3086 - val_mrcnn_bbox_loss: 0.2626 - val_mrcnn_mask_loss: 0.5193\n",
            "Epoch 16/20\n",
            "470/470 [==============================] - 294s 625ms/step - loss: 0.1200 - rpn_class_loss: 7.3312e-04 - rpn_bbox_loss: 0.0264 - mrcnn_class_loss: 0.0236 - mrcnn_bbox_loss: 0.0128 - mrcnn_mask_loss: 0.0565 - val_loss: 1.7294 - val_rpn_class_loss: 0.0858 - val_rpn_bbox_loss: 0.5250 - val_mrcnn_class_loss: 0.3577 - val_mrcnn_bbox_loss: 0.2297 - val_mrcnn_mask_loss: 0.5313\n",
            "Epoch 17/20\n",
            "470/470 [==============================] - 291s 620ms/step - loss: 0.1303 - rpn_class_loss: 7.2175e-04 - rpn_bbox_loss: 0.0362 - mrcnn_class_loss: 0.0232 - mrcnn_bbox_loss: 0.0134 - mrcnn_mask_loss: 0.0567 - val_loss: 1.8441 - val_rpn_class_loss: 0.0939 - val_rpn_bbox_loss: 0.4907 - val_mrcnn_class_loss: 0.4911 - val_mrcnn_bbox_loss: 0.2484 - val_mrcnn_mask_loss: 0.5200\n",
            "Epoch 18/20\n",
            "470/470 [==============================] - 298s 633ms/step - loss: 0.1231 - rpn_class_loss: 6.5287e-04 - rpn_bbox_loss: 0.0317 - mrcnn_class_loss: 0.0232 - mrcnn_bbox_loss: 0.0128 - mrcnn_mask_loss: 0.0547 - val_loss: 1.7424 - val_rpn_class_loss: 0.0971 - val_rpn_bbox_loss: 0.4934 - val_mrcnn_class_loss: 0.3409 - val_mrcnn_bbox_loss: 0.2470 - val_mrcnn_mask_loss: 0.5641\n",
            "Epoch 19/20\n",
            "470/470 [==============================] - 295s 628ms/step - loss: 0.0979 - rpn_class_loss: 4.8621e-04 - rpn_bbox_loss: 0.0171 - mrcnn_class_loss: 0.0196 - mrcnn_bbox_loss: 0.0095 - mrcnn_mask_loss: 0.0513 - val_loss: 1.8191 - val_rpn_class_loss: 0.0877 - val_rpn_bbox_loss: 0.4684 - val_mrcnn_class_loss: 0.4386 - val_mrcnn_bbox_loss: 0.2510 - val_mrcnn_mask_loss: 0.5734\n",
            "Epoch 20/20\n",
            "470/470 [==============================] - 294s 626ms/step - loss: 0.0971 - rpn_class_loss: 4.5336e-04 - rpn_bbox_loss: 0.0171 - mrcnn_class_loss: 0.0198 - mrcnn_bbox_loss: 0.0087 - mrcnn_mask_loss: 0.0510 - val_loss: 2.0699 - val_rpn_class_loss: 0.1201 - val_rpn_bbox_loss: 0.5064 - val_mrcnn_class_loss: 0.5666 - val_mrcnn_bbox_loss: 0.2482 - val_mrcnn_mask_loss: 0.6286\n",
            "\n",
            "Starting at epoch 20. LR=0.0005\n",
            "\n",
            "Checkpoint Path: /content/drive/My Drive/TFG/Submision/Weight_decay/cucumber_cfg20200605T1806/mask_rcnn_cucumber_cfg_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/30\n",
            "470/470 [==============================] - 447s 951ms/step - loss: 0.1776 - rpn_class_loss: 9.7565e-04 - rpn_bbox_loss: 0.0480 - mrcnn_class_loss: 0.0312 - mrcnn_bbox_loss: 0.0272 - mrcnn_mask_loss: 0.0703 - val_loss: 1.5427 - val_rpn_class_loss: 0.0481 - val_rpn_bbox_loss: 0.4308 - val_mrcnn_class_loss: 0.3758 - val_mrcnn_bbox_loss: 0.2307 - val_mrcnn_mask_loss: 0.4573\n",
            "Epoch 22/30\n",
            "470/470 [==============================] - 397s 845ms/step - loss: 0.1717 - rpn_class_loss: 6.3427e-04 - rpn_bbox_loss: 0.0473 - mrcnn_class_loss: 0.0297 - mrcnn_bbox_loss: 0.0247 - mrcnn_mask_loss: 0.0694 - val_loss: 1.4691 - val_rpn_class_loss: 0.0542 - val_rpn_bbox_loss: 0.3842 - val_mrcnn_class_loss: 0.3678 - val_mrcnn_bbox_loss: 0.2121 - val_mrcnn_mask_loss: 0.4508\n",
            "Epoch 23/30\n",
            "470/470 [==============================] - 396s 844ms/step - loss: 0.1331 - rpn_class_loss: 4.0194e-04 - rpn_bbox_loss: 0.0299 - mrcnn_class_loss: 0.0243 - mrcnn_bbox_loss: 0.0169 - mrcnn_mask_loss: 0.0615 - val_loss: 1.4678 - val_rpn_class_loss: 0.0728 - val_rpn_bbox_loss: 0.4116 - val_mrcnn_class_loss: 0.3758 - val_mrcnn_bbox_loss: 0.2092 - val_mrcnn_mask_loss: 0.3983\n",
            "Epoch 24/30\n",
            "470/470 [==============================] - 396s 842ms/step - loss: 0.1225 - rpn_class_loss: 2.9358e-04 - rpn_bbox_loss: 0.0275 - mrcnn_class_loss: 0.0216 - mrcnn_bbox_loss: 0.0145 - mrcnn_mask_loss: 0.0587 - val_loss: 1.5510 - val_rpn_class_loss: 0.1036 - val_rpn_bbox_loss: 0.4177 - val_mrcnn_class_loss: 0.4007 - val_mrcnn_bbox_loss: 0.2054 - val_mrcnn_mask_loss: 0.4236\n",
            "Epoch 25/30\n",
            "470/470 [==============================] - 396s 842ms/step - loss: 0.1095 - rpn_class_loss: 2.4177e-04 - rpn_bbox_loss: 0.0207 - mrcnn_class_loss: 0.0194 - mrcnn_bbox_loss: 0.0127 - mrcnn_mask_loss: 0.0565 - val_loss: 1.4219 - val_rpn_class_loss: 0.0685 - val_rpn_bbox_loss: 0.3717 - val_mrcnn_class_loss: 0.3544 - val_mrcnn_bbox_loss: 0.2026 - val_mrcnn_mask_loss: 0.4246\n",
            "Epoch 26/30\n",
            "470/470 [==============================] - 395s 839ms/step - loss: 0.1218 - rpn_class_loss: 2.7010e-04 - rpn_bbox_loss: 0.0298 - mrcnn_class_loss: 0.0192 - mrcnn_bbox_loss: 0.0145 - mrcnn_mask_loss: 0.0580 - val_loss: 1.6876 - val_rpn_class_loss: 0.1303 - val_rpn_bbox_loss: 0.4577 - val_mrcnn_class_loss: 0.4434 - val_mrcnn_bbox_loss: 0.2269 - val_mrcnn_mask_loss: 0.4294\n",
            "Epoch 27/30\n",
            "470/470 [==============================] - 392s 835ms/step - loss: 0.1157 - rpn_class_loss: 2.7656e-04 - rpn_bbox_loss: 0.0290 - mrcnn_class_loss: 0.0187 - mrcnn_bbox_loss: 0.0131 - mrcnn_mask_loss: 0.0546 - val_loss: 1.6581 - val_rpn_class_loss: 0.1313 - val_rpn_bbox_loss: 0.4716 - val_mrcnn_class_loss: 0.4144 - val_mrcnn_bbox_loss: 0.2084 - val_mrcnn_mask_loss: 0.4324\n",
            "Epoch 28/30\n",
            "470/470 [==============================] - 397s 844ms/step - loss: 0.1209 - rpn_class_loss: 2.7741e-04 - rpn_bbox_loss: 0.0308 - mrcnn_class_loss: 0.0197 - mrcnn_bbox_loss: 0.0148 - mrcnn_mask_loss: 0.0554 - val_loss: 1.4522 - val_rpn_class_loss: 0.0724 - val_rpn_bbox_loss: 0.4039 - val_mrcnn_class_loss: 0.3639 - val_mrcnn_bbox_loss: 0.1872 - val_mrcnn_mask_loss: 0.4247\n",
            "Epoch 29/30\n",
            "470/470 [==============================] - 394s 838ms/step - loss: 0.1037 - rpn_class_loss: 2.7902e-04 - rpn_bbox_loss: 0.0241 - mrcnn_class_loss: 0.0165 - mrcnn_bbox_loss: 0.0116 - mrcnn_mask_loss: 0.0512 - val_loss: 1.6134 - val_rpn_class_loss: 0.0999 - val_rpn_bbox_loss: 0.4262 - val_mrcnn_class_loss: 0.4396 - val_mrcnn_bbox_loss: 0.2076 - val_mrcnn_mask_loss: 0.4400\n",
            "Epoch 30/30\n",
            "470/470 [==============================] - 394s 837ms/step - loss: 0.1073 - rpn_class_loss: 2.9133e-04 - rpn_bbox_loss: 0.0230 - mrcnn_class_loss: 0.0192 - mrcnn_bbox_loss: 0.0127 - mrcnn_mask_loss: 0.0520 - val_loss: 1.6811 - val_rpn_class_loss: 0.1153 - val_rpn_bbox_loss: 0.4333 - val_mrcnn_class_loss: 0.4676 - val_mrcnn_bbox_loss: 0.2054 - val_mrcnn_mask_loss: 0.4595\n",
            "\n",
            "Starting at epoch 30. LR=0.0001\n",
            "\n",
            "Checkpoint Path: /content/drive/My Drive/TFG/Submision/Weight_decay/cucumber_cfg20200605T1806/mask_rcnn_cucumber_cfg_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/45\n",
            "117/470 [======>.......................] - ETA: 8:06 - loss: 0.0923 - rpn_class_loss: 2.0883e-04 - rpn_bbox_loss: 0.0190 - mrcnn_class_loss: 0.0157 - mrcnn_bbox_loss: 0.0089 - mrcnn_mask_loss: 0.0485Epoch 31/45\n",
            "469/470 [============================>.] - ETA: 0s - loss: 0.0709 - rpn_class_loss: 2.0278e-04 - rpn_bbox_loss: 0.0079 - mrcnn_class_loss: 0.0125 - mrcnn_bbox_loss: 0.0057 - mrcnn_mask_loss: 0.0446Epoch 31/45\n",
            "470/470 [==============================] - 513s 1s/step - loss: 0.0709 - rpn_class_loss: 2.0296e-04 - rpn_bbox_loss: 0.0079 - mrcnn_class_loss: 0.0125 - mrcnn_bbox_loss: 0.0057 - mrcnn_mask_loss: 0.0446 - val_loss: 1.7510 - val_rpn_class_loss: 0.1172 - val_rpn_bbox_loss: 0.4262 - val_mrcnn_class_loss: 0.4995 - val_mrcnn_bbox_loss: 0.1921 - val_mrcnn_mask_loss: 0.5159\n",
            "Epoch 32/45\n",
            "470/470 [==============================] - 452s 961ms/step - loss: 0.0572 - rpn_class_loss: 1.8899e-04 - rpn_bbox_loss: 0.0021 - mrcnn_class_loss: 0.0099 - mrcnn_bbox_loss: 0.0033 - mrcnn_mask_loss: 0.0417 - val_loss: 1.6943 - val_rpn_class_loss: 0.0998 - val_rpn_bbox_loss: 0.3902 - val_mrcnn_class_loss: 0.5008 - val_mrcnn_bbox_loss: 0.1847 - val_mrcnn_mask_loss: 0.5187\n",
            "Epoch 33/45\n",
            "470/470 [==============================] - 453s 964ms/step - loss: 0.0539 - rpn_class_loss: 1.7654e-04 - rpn_bbox_loss: 0.0015 - mrcnn_class_loss: 0.0089 - mrcnn_bbox_loss: 0.0028 - mrcnn_mask_loss: 0.0405 - val_loss: 1.8077 - val_rpn_class_loss: 0.1244 - val_rpn_bbox_loss: 0.4457 - val_mrcnn_class_loss: 0.5235 - val_mrcnn_bbox_loss: 0.2007 - val_mrcnn_mask_loss: 0.5135\n",
            "Epoch 34/45\n",
            "470/470 [==============================] - 450s 957ms/step - loss: 0.0519 - rpn_class_loss: 1.6756e-04 - rpn_bbox_loss: 0.0013 - mrcnn_class_loss: 0.0081 - mrcnn_bbox_loss: 0.0024 - mrcnn_mask_loss: 0.0398 - val_loss: 1.8652 - val_rpn_class_loss: 0.1244 - val_rpn_bbox_loss: 0.4322 - val_mrcnn_class_loss: 0.5540 - val_mrcnn_bbox_loss: 0.1961 - val_mrcnn_mask_loss: 0.5585\n",
            "Epoch 35/45\n",
            "470/470 [==============================] - 450s 956ms/step - loss: 0.0503 - rpn_class_loss: 1.6022e-04 - rpn_bbox_loss: 0.0012 - mrcnn_class_loss: 0.0075 - mrcnn_bbox_loss: 0.0023 - mrcnn_mask_loss: 0.0391 - val_loss: 1.7546 - val_rpn_class_loss: 0.1050 - val_rpn_bbox_loss: 0.3892 - val_mrcnn_class_loss: 0.5194 - val_mrcnn_bbox_loss: 0.1844 - val_mrcnn_mask_loss: 0.5566\n",
            "Epoch 36/45\n",
            "470/470 [==============================] - 449s 956ms/step - loss: 0.0490 - rpn_class_loss: 1.5291e-04 - rpn_bbox_loss: 0.0011 - mrcnn_class_loss: 0.0070 - mrcnn_bbox_loss: 0.0021 - mrcnn_mask_loss: 0.0385 - val_loss: 1.8142 - val_rpn_class_loss: 0.1151 - val_rpn_bbox_loss: 0.4228 - val_mrcnn_class_loss: 0.5509 - val_mrcnn_bbox_loss: 0.1955 - val_mrcnn_mask_loss: 0.5299\n",
            "Epoch 37/45\n",
            "470/470 [==============================] - 449s 956ms/step - loss: 0.0479 - rpn_class_loss: 1.4498e-04 - rpn_bbox_loss: 9.8107e-04 - mrcnn_class_loss: 0.0066 - mrcnn_bbox_loss: 0.0021 - mrcnn_mask_loss: 0.0381 - val_loss: 1.9039 - val_rpn_class_loss: 0.1187 - val_rpn_bbox_loss: 0.4294 - val_mrcnn_class_loss: 0.5962 - val_mrcnn_bbox_loss: 0.1967 - val_mrcnn_mask_loss: 0.5627\n",
            "Epoch 38/45\n",
            "470/470 [==============================] - 452s 962ms/step - loss: 0.0479 - rpn_class_loss: 1.4062e-04 - rpn_bbox_loss: 0.0010 - mrcnn_class_loss: 0.0064 - mrcnn_bbox_loss: 0.0020 - mrcnn_mask_loss: 0.0383 - val_loss: 1.8716 - val_rpn_class_loss: 0.1066 - val_rpn_bbox_loss: 0.4052 - val_mrcnn_class_loss: 0.5796 - val_mrcnn_bbox_loss: 0.1911 - val_mrcnn_mask_loss: 0.5891\n",
            "Epoch 39/45\n",
            "470/470 [==============================] - 451s 960ms/step - loss: 0.0496 - rpn_class_loss: 1.4394e-04 - rpn_bbox_loss: 0.0016 - mrcnn_class_loss: 0.0075 - mrcnn_bbox_loss: 0.0022 - mrcnn_mask_loss: 0.0382 - val_loss: 1.8679 - val_rpn_class_loss: 0.1057 - val_rpn_bbox_loss: 0.4028 - val_mrcnn_class_loss: 0.6018 - val_mrcnn_bbox_loss: 0.1912 - val_mrcnn_mask_loss: 0.5663\n",
            "Epoch 40/45\n",
            "470/470 [==============================] - 451s 960ms/step - loss: 0.0470 - rpn_class_loss: 1.3091e-04 - rpn_bbox_loss: 9.3185e-04 - mrcnn_class_loss: 0.0068 - mrcnn_bbox_loss: 0.0019 - mrcnn_mask_loss: 0.0373 - val_loss: 1.9010 - val_rpn_class_loss: 0.1224 - val_rpn_bbox_loss: 0.4410 - val_mrcnn_class_loss: 0.5824 - val_mrcnn_bbox_loss: 0.2028 - val_mrcnn_mask_loss: 0.5523\n",
            "Epoch 41/45\n",
            "470/470 [==============================] - 448s 954ms/step - loss: 0.0465 - rpn_class_loss: 1.2638e-04 - rpn_bbox_loss: 8.9442e-04 - mrcnn_class_loss: 0.0063 - mrcnn_bbox_loss: 0.0019 - mrcnn_mask_loss: 0.0373 - val_loss: 1.9589 - val_rpn_class_loss: 0.1228 - val_rpn_bbox_loss: 0.4366 - val_mrcnn_class_loss: 0.6041 - val_mrcnn_bbox_loss: 0.2060 - val_mrcnn_mask_loss: 0.5894\n",
            "Epoch 42/45\n",
            "470/470 [==============================] - 450s 956ms/step - loss: 0.0467 - rpn_class_loss: 1.2008e-04 - rpn_bbox_loss: 8.7043e-04 - mrcnn_class_loss: 0.0067 - mrcnn_bbox_loss: 0.0018 - mrcnn_mask_loss: 0.0371 - val_loss: 1.8084 - val_rpn_class_loss: 0.0968 - val_rpn_bbox_loss: 0.3836 - val_mrcnn_class_loss: 0.5717 - val_mrcnn_bbox_loss: 0.1841 - val_mrcnn_mask_loss: 0.5723\n",
            "Epoch 43/45\n",
            "470/470 [==============================] - 450s 958ms/step - loss: 0.0462 - rpn_class_loss: 1.1568e-04 - rpn_bbox_loss: 8.4373e-04 - mrcnn_class_loss: 0.0063 - mrcnn_bbox_loss: 0.0019 - mrcnn_mask_loss: 0.0370 - val_loss: 1.9160 - val_rpn_class_loss: 0.1244 - val_rpn_bbox_loss: 0.4446 - val_mrcnn_class_loss: 0.5993 - val_mrcnn_bbox_loss: 0.1992 - val_mrcnn_mask_loss: 0.5484\n",
            "Epoch 44/45\n",
            "470/470 [==============================] - 447s 951ms/step - loss: 0.0449 - rpn_class_loss: 1.1275e-04 - rpn_bbox_loss: 8.0995e-04 - mrcnn_class_loss: 0.0055 - mrcnn_bbox_loss: 0.0018 - mrcnn_mask_loss: 0.0366 - val_loss: 1.9326 - val_rpn_class_loss: 0.1216 - val_rpn_bbox_loss: 0.4349 - val_mrcnn_class_loss: 0.6049 - val_mrcnn_bbox_loss: 0.2002 - val_mrcnn_mask_loss: 0.5709\n",
            "Epoch 45/45\n",
            "470/470 [==============================] - 449s 956ms/step - loss: 0.0446 - rpn_class_loss: 1.0781e-04 - rpn_bbox_loss: 7.5678e-04 - mrcnn_class_loss: 0.0056 - mrcnn_bbox_loss: 0.0017 - mrcnn_mask_loss: 0.0364 - val_loss: 1.8379 - val_rpn_class_loss: 0.1068 - val_rpn_bbox_loss: 0.4015 - val_mrcnn_class_loss: 0.5629 - val_mrcnn_bbox_loss: 0.1874 - val_mrcnn_mask_loss: 0.5792\n",
            "Elapsed time 282.3 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1urZ14nK1cs",
        "colab_type": "text"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDsKfXj5K6OQ",
        "colab_type": "text"
      },
      "source": [
        "Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw2HYRebKzGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content/drive/My Drive/TFG/Via\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "from samples.balloon import cucumber\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Path to Ballon trained weights\n",
        "# You can download this file from the Releases page\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "cucumber_WEIGHTS_PATH = \"/content/drive/My Drive/TFG/Submision/Finetune_noaug/cucumber_cfg20200604T1202/mask_rcnn_cucumber_cfg_0045.h5\"  # TODO: update this path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghf0QSoBLCzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = cucumber.cucumberConfig()\n",
        "cucumber_DIR = cucumber_DIR = \"/content/drive/My Drive/TFG/Via\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ls7Wyz8LE19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Override the training configurations with a few\n",
        "# changes for inferencing.\n",
        "class InferenceConfig(config.__class__):\n",
        "    # Run detection on one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttaKfumRLIfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device to load the neural network on.\n",
        "# Useful if you're training a model on the same \n",
        "# machine, in which case use CPU and leave the\n",
        "# GPU for training.\n",
        "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# TODO: code for 'training' test mode not ready yet\n",
        "TEST_MODE = \"inference\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d1Hrza6LLlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load validation dataset\n",
        "dataset = cucumber.cucumberDataset()\n",
        "dataset.load_cucumber(cucumber_DIR, \"val\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMvH2PExLM-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9GbbghOLO7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set path to balloon weights file\n",
        "\n",
        "# Download file from the Releases page and set its path\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "# weights_path = \"/path/to/mask_rcnn_balloon.h5\"\n",
        "\n",
        "# Or, load the last model you trained\n",
        "weights_path = \"/content/drive/My Drive/TFG/Submision/Finetune_noaug/cucumber_cfg20200604T1202/mask_rcnn_cucumber_cfg_0045.h5\"\n",
        "\n",
        "# Load weights\n",
        "print(\"Loading weights \", weights_path)\n",
        "model.load_weights(weights_path, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fccHSQvuLJ33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7azDnKbLW15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_id = random.choice(dataset.image_ids)\n",
        "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "info = dataset.image_info[image_id]\n",
        "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                       dataset.image_reference(image_id)))\n",
        "\n",
        "# Run object detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Display results\n",
        "ax = get_ax(1)\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset.class_names, r['scores'], ax=ax,\n",
        "                            title=\"Predictions\")\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSJritxKS-9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splash = cucumber.color_splash(image, r['masks'])\n",
        "display_images([splash], cols=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHGW0kdYKg_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw precision-recall curve\n",
        "AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                                          r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
        "visualize.plot_precision_recall(AP, precisions, recalls)\n",
        "print(AP, recalls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhDK7kzTKe1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute VOC-style Average Precision\n",
        "def compute_batch_ap(image_ids):\n",
        "    APs = []\n",
        "    for image_id in image_ids:\n",
        "        # Load image\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(dataset, config,\n",
        "                                   image_id, use_mini_mask=False)\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        # Compute AP\n",
        "        r = results[0]\n",
        "        AP, precisions, recalls, overlaps =\\\n",
        "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                              r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
        "        APs.append(AP)\n",
        "    return APs\n",
        "\n",
        "# Pick a set of random images\n",
        "image_ids = np.random.choice(dataset.image_ids, 53)\n",
        "APs = compute_batch_ap(image_ids)\n",
        "print(\"mAP @ IoU=50: \", np.mean(APs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1wcf4MPTqqr",
        "colab_type": "text"
      },
      "source": [
        "## RPN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2FP34dKTkDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate RPN trainig targets\n",
        "# target_rpn_match is 1 for positive anchors, -1 for negative anchors\n",
        "# and 0 for neutral anchors.\n",
        "target_rpn_match, target_rpn_bbox = modellib.build_rpn_targets(\n",
        "    image.shape, model.anchors, gt_class_id, gt_bbox, model.config)\n",
        "log(\"target_rpn_match\", target_rpn_match)\n",
        "log(\"target_rpn_bbox\", target_rpn_bbox)\n",
        "\n",
        "positive_anchor_ix = np.where(target_rpn_match[:] == 1)[0]\n",
        "negative_anchor_ix = np.where(target_rpn_match[:] == -1)[0]\n",
        "neutral_anchor_ix = np.where(target_rpn_match[:] == 0)[0]\n",
        "positive_anchors = model.anchors[positive_anchor_ix]\n",
        "negative_anchors = model.anchors[negative_anchor_ix]\n",
        "neutral_anchors = model.anchors[neutral_anchor_ix]\n",
        "log(\"positive_anchors\", positive_anchors)\n",
        "log(\"negative_anchors\", negative_anchors)\n",
        "log(\"neutral anchors\", neutral_anchors)\n",
        "\n",
        "# Apply refinement deltas to positive anchors\n",
        "refined_anchors = utils.apply_box_deltas(\n",
        "    positive_anchors,\n",
        "    target_rpn_bbox[:positive_anchors.shape[0]] * model.config.RPN_BBOX_STD_DEV)\n",
        "log(\"refined_anchors\", refined_anchors, )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7zXFu4tTvkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display positive anchors before refinement (dotted) and\n",
        "# after refinement (solid).\n",
        "visualize.draw_boxes(image, boxes=positive_anchors, refined_boxes=refined_anchors, ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfYPo5OKT0XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run RPN sub-graph\n",
        "pillar = model.keras_model.get_layer(\"ROI\").output  # node to start searching from\n",
        "\n",
        "# TF 1.4 and 1.9 introduce new versions of NMS. Search for all names to support TF 1.3~1.10\n",
        "nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression:0\")\n",
        "if nms_node is None:\n",
        "    nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV2:0\")\n",
        "if nms_node is None: #TF 1.9-1.10\n",
        "    nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV3:0\")\n",
        "\n",
        "rpn = model.run_graph([image], [\n",
        "    (\"rpn_class\", model.keras_model.get_layer(\"rpn_class\").output),\n",
        "    (\"pre_nms_anchors\", model.ancestor(pillar, \"ROI/pre_nms_anchors:0\")),\n",
        "    (\"refined_anchors\", model.ancestor(pillar, \"ROI/refined_anchors:0\")),\n",
        "    (\"refined_anchors_clipped\", model.ancestor(pillar, \"ROI/refined_anchors_clipped:0\")),\n",
        "    (\"post_nms_anchor_ix\", nms_node),\n",
        "    (\"proposals\", model.keras_model.get_layer(\"ROI\").output),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0pJqn6DT10p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show top anchors by score (before refinement)\n",
        "limit = 100\n",
        "sorted_anchor_ids = np.argsort(rpn['rpn_class'][:,:,1].flatten())[::-1]\n",
        "visualize.draw_boxes(image, boxes=model.anchors[sorted_anchor_ids[:limit]], ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsj9VeVOT4eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show top anchors with refinement. Then with clipping to image boundaries\n",
        "limit = 50\n",
        "ax = get_ax(1, 2)\n",
        "pre_nms_anchors = utils.denorm_boxes(rpn[\"pre_nms_anchors\"][0], image.shape[:2])\n",
        "refined_anchors = utils.denorm_boxes(rpn[\"refined_anchors\"][0], image.shape[:2])\n",
        "refined_anchors_clipped = utils.denorm_boxes(rpn[\"refined_anchors_clipped\"][0], image.shape[:2])\n",
        "visualize.draw_boxes(image, boxes=pre_nms_anchors[:limit],\n",
        "                     refined_boxes=refined_anchors[:limit], ax=ax[0])\n",
        "visualize.draw_boxes(image, refined_boxes=refined_anchors_clipped[:limit], ax=ax[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaWeznmBUqT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show refined anchors after non-max suppression\n",
        "limit = 50\n",
        "ixs = rpn[\"post_nms_anchor_ix\"][:limit]\n",
        "visualize.draw_boxes(image, refined_boxes=refined_anchors_clipped[ixs], ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyulzFOpUsct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show final proposals\n",
        "# These are the same as the previous step (refined anchors \n",
        "# after NMS) but with coordinates normalized to [0, 1] range.\n",
        "limit = 50\n",
        "# Convert back to image coordinates for display\n",
        "h, w = config.IMAGE_SHAPE[:2]\n",
        "proposals = rpn['proposals'][0, :limit] * np.array([h, w, h, w])\n",
        "visualize.draw_boxes(image, refined_boxes=proposals, ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNSTZY5qUxL_",
        "colab_type": "text"
      },
      "source": [
        "## Proposal Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TrWZpRiUzx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get input and output to classifier and mask heads.\n",
        "mrcnn = model.run_graph([image], [\n",
        "    (\"proposals\", model.keras_model.get_layer(\"ROI\").output),\n",
        "    (\"probs\", model.keras_model.get_layer(\"mrcnn_class\").output),\n",
        "    (\"deltas\", model.keras_model.get_layer(\"mrcnn_bbox\").output),\n",
        "    (\"masks\", model.keras_model.get_layer(\"mrcnn_mask\").output),\n",
        "    (\"detections\", model.keras_model.get_layer(\"mrcnn_detection\").output),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwRpuVZKU1_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get detection class IDs. Trim zero padding.\n",
        "det_class_ids = mrcnn['detections'][0, :, 4].astype(np.int32)\n",
        "det_count = np.where(det_class_ids == 0)[0][0]\n",
        "det_class_ids = det_class_ids[:det_count]\n",
        "detections = mrcnn['detections'][0, :det_count]\n",
        "\n",
        "print(\"{} detections: {}\".format(\n",
        "    det_count, np.array(dataset.class_names)[det_class_ids]))\n",
        "\n",
        "captions = [\"{} {:.3f}\".format(dataset.class_names[int(c)], s) if c > 0 else \"\"\n",
        "            for c, s in zip(detections[:, 4], detections[:, 5])]\n",
        "visualize.draw_boxes(\n",
        "    image, \n",
        "    refined_boxes=utils.denorm_boxes(detections[:, :4], image.shape[:2]),\n",
        "    visibilities=[2] * len(detections),\n",
        "    captions=captions, title=\"Detections\",\n",
        "    ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pczWbRqcVHNt",
        "colab_type": "text"
      },
      "source": [
        "## Bounding Box Refinement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLVUiJ-fVGOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class-specific bounding box shifts.\n",
        "roi_bbox_specific = mrcnn[\"deltas\"][0, np.arange(proposals.shape[0]), roi_class_ids]\n",
        "log(\"roi_bbox_specific\", roi_bbox_specific)\n",
        "\n",
        "# Apply bounding box transformations\n",
        "# Shape: [N, (y1, x1, y2, x2)]\n",
        "refined_proposals = utils.apply_box_deltas(\n",
        "    proposals, roi_bbox_specific * config.BBOX_STD_DEV).astype(np.int32)\n",
        "log(\"refined_proposals\", refined_proposals)\n",
        "\n",
        "# Show positive proposals\n",
        "# ids = np.arange(roi_boxes.shape[0])  # Display all\n",
        "limit = 5\n",
        "ids = np.random.randint(0, len(roi_positive_ixs), limit)  # Display random sample\n",
        "captions = [\"{} {:.3f}\".format(dataset.class_names[c], s) if c > 0 else \"\"\n",
        "            for c, s in zip(roi_class_ids[roi_positive_ixs][ids], roi_scores[roi_positive_ixs][ids])]\n",
        "visualize.draw_boxes(image, boxes=proposals[roi_positive_ixs][ids],\n",
        "                     refined_boxes=refined_proposals[roi_positive_ixs][ids],\n",
        "                     visibilities=np.where(roi_class_ids[roi_positive_ixs][ids] > 0, 1, 0),\n",
        "                     captions=captions, title=\"ROIs After Refinement\",\n",
        "                     ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jck-F4cwVQIl",
        "colab_type": "text"
      },
      "source": [
        "## Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkaBjxzYVPSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_images(np.transpose(gt_mask, [2, 0, 1]), cmap=\"Blues\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7z5yzY2VU8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get predictions of mask head\n",
        "mrcnn = model.run_graph([image], [\n",
        "    (\"detections\", model.keras_model.get_layer(\"mrcnn_detection\").output),\n",
        "    (\"masks\", model.keras_model.get_layer(\"mrcnn_mask\").output),\n",
        "])\n",
        "\n",
        "# Get detection class IDs. Trim zero padding.\n",
        "det_class_ids = mrcnn['detections'][0, :, 4].astype(np.int32)\n",
        "det_count = np.where(det_class_ids == 0)[0][0]\n",
        "det_class_ids = det_class_ids[:det_count]\n",
        "\n",
        "print(\"{} detections: {}\".format(\n",
        "    det_count, np.array(dataset.class_names)[det_class_ids]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xng-1W_sVWT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Masks\n",
        "det_boxes = utils.denorm_boxes(mrcnn[\"detections\"][0, :, :4], image.shape[:2])\n",
        "det_mask_specific = np.array([mrcnn[\"masks\"][0, i, :, :, c] \n",
        "                              for i, c in enumerate(det_class_ids)])\n",
        "det_masks = np.array([utils.unmold_mask(m, det_boxes[i], image.shape)\n",
        "                      for i, m in enumerate(det_mask_specific)])\n",
        "log(\"det_mask_specific\", det_mask_specific)\n",
        "log(\"det_masks\", det_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzIhTNgVVXW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_images(det_mask_specific[:4] * 255, cmap=\"Blues\", interpolation=\"none\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewiSyxZhVb0W",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Layer activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXMpaNL0Va0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get activations of a few sample layers\n",
        "activations = model.run_graph([image], [\n",
        "    (\"input_image\",        tf.identity(model.keras_model.get_layer(\"input_image\").output)),\n",
        "    (\"res2c_out\",          model.keras_model.get_layer(\"res2c_out\").output),\n",
        "    (\"res3c_out\",          model.keras_model.get_layer(\"res3c_out\").output),\n",
        "    (\"res4w_out\",          model.keras_model.get_layer(\"res4w_out\").output),  # for resnet100\n",
        "    (\"rpn_bbox\",           model.keras_model.get_layer(\"rpn_bbox\").output),\n",
        "    (\"roi\",                model.keras_model.get_layer(\"ROI\").output),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNfD-RfxVg-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input image (normalized)\n",
        "_ = plt.imshow(modellib.unmold_image(activations[\"input_image\"][0],config))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUwCI_WfViSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Backbone feature map\n",
        "display_images(np.transpose(activations[\"res2c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4XvfqnKWLTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Backbone feature map\n",
        "display_images(np.transpose(activations[\"res3c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T22yS8xLWL-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Backbone feature map\n",
        "display_images(np.transpose(activations[\"res4w_out\"][0,:,:,:4], [2, 0, 1]), cols=4)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}